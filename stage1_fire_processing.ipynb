{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement\n",
    "\n",
    "Utitilzed chatGPT for assistance with some code in this notebook. Reference sections below for specific prompts used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update to include info about calculation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intermediate_file_paths.json') as output_path_file:\n",
    "    output_paths = json.load(output_path_file)\n",
    "\n",
    "\n",
    "FIRE_INPUT_PATH = output_paths.get('stage0_fire_json')\n",
    "#FIRE_INPUT_PATH = output_paths.get('POC_stage0_fire_json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI_PER_FIRE_OUTPUT_PATH = output_paths.get('stage1_si_per_fire_csv')\n",
    "SI_PER_YEAR_OUTPUT_PATH = output_paths.get(\"stage1_si_per_year_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FIRE_INPUT_PATH) as fire_file:\n",
    "    fire_data = geojson.load(fire_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the number of records and ensure all have the same keys\n",
    "def check_records(data, record_type=\"Record\"):\n",
    "    # Get the set of keys from the first record\n",
    "    first_record_keys = set(data[0].get('attributes', {}).keys())\n",
    "\n",
    "    # Initialize a list to collect error records and a counter for mismatches\n",
    "    error_records = []\n",
    "    mismatched_count = 0\n",
    "\n",
    "    # Iterate through all records to compare the keys\n",
    "    for index, feature in enumerate(data):\n",
    "        current_keys = set(feature.get('attributes', {}).keys())\n",
    "\n",
    "        # Check if the keys match with the first record's keys\n",
    "        if current_keys != first_record_keys:\n",
    "            mismatched_count += 1\n",
    "            print(f\"{record_type} {index} has a different set of keys.\")\n",
    "            print(f\"Expected keys: {first_record_keys}\")\n",
    "            print(f\"Found keys: {current_keys}\")\n",
    "            \n",
    "            # Add the mismatched record to the error list\n",
    "            error_records.append(feature)\n",
    "\n",
    "    # Final report\n",
    "    total_records = len(data)\n",
    "    print(f\"\\nTotal number of {record_type.lower()}s: {total_records}\")\n",
    "    \n",
    "    if mismatched_count == 0:\n",
    "        print(f\"All {record_type.lower()}s contain the same set of keys.\")\n",
    "    else:\n",
    "        print(f\"{mismatched_count} {record_type.lower()}s have mismatched keys.\")\n",
    "\n",
    "    # Return the error records if there are any mismatches\n",
    "    return error_records, first_record_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking fire_data...\n",
      "\n",
      "Total number of fire data records: 101906\n",
      "All fire data records contain the same set of keys.\n"
     ]
    }
   ],
   "source": [
    "# Check the fire_data and features_with_smoke_impact\n",
    "print(\"\\nChecking fire_data...\")\n",
    "fire_data_errors, fire_data_keys = check_records(fire_data['features'], record_type=\"Fire data record\")\n",
    "\n",
    "# Optional: You can save the error records for later analysis\n",
    "if fire_data_errors:\n",
    "    with open('fire_data_error_records.json', 'w') as fire_error_file:\n",
    "        json.dump({\"features\": fire_data_errors}, fire_error_file, indent=4)\n",
    "    print(\"Fire data error records have been written to 'fire_data_error_records.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of fire attributes from each feature\n",
    "fire_attributes = [feature['attributes'] for feature in fire_data['features']]\n",
    "\n",
    "# Convert the list of attributes dictionaries to a DataFrame\n",
    "fire_df = pd.DataFrame(fire_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OBJECTID', 'USGS_Assigned_ID', 'Assigned_Fire_Type', 'Fire_Year',\n",
      "       'Fire_Polygon_Tier', 'Fire_Attribute_Tiers', 'GIS_Acres',\n",
      "       'GIS_Hectares', 'Source_Datasets', 'Listed_Fire_Types',\n",
      "       'Listed_Fire_Names', 'Listed_Fire_Codes', 'Listed_Fire_IDs',\n",
      "       'Listed_Fire_IRWIN_IDs', 'Listed_Fire_Dates', 'Listed_Fire_Causes',\n",
      "       'Listed_Fire_Cause_Class', 'Listed_Rx_Reported_Acres',\n",
      "       'Listed_Map_Digitize_Methods', 'Listed_Notes', 'Processing_Notes',\n",
      "       'Wildfire_Notice', 'Prescribed_Burn_Notice', 'Wildfire_and_Rx_Flag',\n",
      "       'Overlap_Within_1_or_2_Flag', 'Circleness_Scale', 'Circle_Flag',\n",
      "       'Exclude_From_Summary_Rasters', 'Shape_Length', 'Shape_Area',\n",
      "       'distance'],\n",
      "      dtype='object')\n",
      "Number of rows: 101906\n"
     ]
    }
   ],
   "source": [
    "print(fire_df.columns)\n",
    "print(f\"Number of rows: {fire_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID  USGS_Assigned_ID Assigned_Fire_Type  Fire_Year  \\\n",
      "0     14600             14600           Wildfire       1964   \n",
      "1     14602             14602           Wildfire       1964   \n",
      "2     14605             14605           Wildfire       1964   \n",
      "3     14606             14606           Wildfire       1964   \n",
      "4     14607             14607           Wildfire       1964   \n",
      "\n",
      "   Fire_Polygon_Tier Fire_Attribute_Tiers     GIS_Acres  GIS_Hectares  \\\n",
      "0                  1         1 (1), 3 (3)  65338.877636  26441.705659   \n",
      "1                  1         1 (2), 3 (3)  19218.105903   7777.291530   \n",
      "2                  1         1 (2), 3 (4)  14101.443662   5706.651785   \n",
      "3                  1         1 (2), 3 (3)  11365.328284   4599.385176   \n",
      "4                  1         1 (1), 3 (1)  11131.171732   4504.625381   \n",
      "\n",
      "                                     Source_Datasets  \\\n",
      "0  Comb_National_NIFC_Interagency_Fire_Perimeter_...   \n",
      "1  Comb_National_NIFC_Interagency_Fire_Perimeter_...   \n",
      "2  Comb_National_NIFC_Interagency_Fire_Perimeter_...   \n",
      "3  Comb_National_NIFC_Interagency_Fire_Perimeter_...   \n",
      "4  Comb_National_NIFC_Interagency_Fire_Perimeter_...   \n",
      "\n",
      "                   Listed_Fire_Types  ...  \\\n",
      "0  Wildfire (3), Likely Wildfire (1)  ...   \n",
      "1  Wildfire (4), Likely Wildfire (1)  ...   \n",
      "2  Wildfire (4), Likely Wildfire (2)  ...   \n",
      "3  Wildfire (4), Likely Wildfire (1)  ...   \n",
      "4                       Wildfire (2)  ...   \n",
      "\n",
      "                                     Wildfire_Notice  \\\n",
      "0  Wildfire mapping prior to 1984 was inconsisten...   \n",
      "1  Wildfire mapping prior to 1984 was inconsisten...   \n",
      "2  Wildfire mapping prior to 1984 was inconsisten...   \n",
      "3  Wildfire mapping prior to 1984 was inconsisten...   \n",
      "4  Wildfire mapping prior to 1984 was inconsisten...   \n",
      "\n",
      "                              Prescribed_Burn_Notice Wildfire_and_Rx_Flag  \\\n",
      "0  Prescribed fire data in this dataset represent...                 None   \n",
      "1  Prescribed fire data in this dataset represent...                 None   \n",
      "2  Prescribed fire data in this dataset represent...                 None   \n",
      "3  Prescribed fire data in this dataset represent...                 None   \n",
      "4  Prescribed fire data in this dataset represent...                 None   \n",
      "\n",
      "  Overlap_Within_1_or_2_Flag Circleness_Scale Circle_Flag  \\\n",
      "0                       None         0.263753         NaN   \n",
      "1                       None         0.138493         NaN   \n",
      "2                       None         0.245135         NaN   \n",
      "3                       None         0.158810         NaN   \n",
      "4                       None         0.323658         NaN   \n",
      "\n",
      "  Exclude_From_Summary_Rasters   Shape_Length    Shape_Area     distance  \n",
      "0                           No  112240.801495  2.644171e+08  1672.227615  \n",
      "1                           No   84004.974692  7.777292e+07  1553.851516  \n",
      "2                           No   54086.991380  5.706652e+07   924.501775  \n",
      "3                           No   60327.567380  4.599385e+07  1607.885527  \n",
      "4                           No   41820.660908  4.504625e+07  1460.298867  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to verify the structure\n",
    "print(fire_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoke Impact Calculations per Fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt used for chatgpt (model 4o): Need some code to get the smoke impact for each fire based on its size and distance away from memphis. also want to use the fire duration to amortize the fire over the fire season. Only reliable data fields to use are fire size (GIS_ACRES) and distance from memphis. Other variables are not reliable. Want to normalize the size and distance factors. Working on this assignment requirement: It seems reasonable that a large fire, that burns a large number of acres, and that is close to a city would put more smoke into a city than a small fire that is much further away. One task is to define your smoke estimate and then apply it to every fire within the specified distance to your city. Should your smoke estimate be cumulative during each year or somehow amortized over the fire season? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for distance and fire duration\n",
    "MIN_FIRE_DURATION = 10  # Minimum duration of a fire in days\n",
    "MAX_FIRE_DURATION = 150  # Maximum duration of a fire in days\n",
    "MAX_DISTANCE = 650       # Maximum distance for considering impact\n",
    "\n",
    "# Define function for estimating fire duration based on size\n",
    "def estimate_fire_duration(gis_acres, max_acres):\n",
    "    normalized_size = gis_acres / max_acres\n",
    "    fire_duration = MIN_FIRE_DURATION + (normalized_size * (MAX_FIRE_DURATION - MIN_FIRE_DURATION))\n",
    "    return max(MIN_FIRE_DURATION, min(fire_duration, MAX_FIRE_DURATION))\n",
    "\n",
    "# Function to calculate smoke impact for each fire\n",
    "def get_smoke_impact(gis_acres, dist_from_memphis, max_acres):\n",
    "    if gis_acres is None or dist_from_memphis is None:\n",
    "        return 0  # Ignore fires with missing data\n",
    "    \n",
    "    # Calculate normalized size and distance factors\n",
    "    size_factor = gis_acres / max_acres\n",
    "    distance_factor = 1 - (dist_from_memphis / MAX_DISTANCE)\n",
    "\n",
    "    # Smoke impact score for this fire\n",
    "    smoke_impact = size_factor * distance_factor\n",
    "    \n",
    "    return max(smoke_impact, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/js/_m5r698x29j4dvr0w18h6jdm0000gn/T/ipykernel_6915/2844685709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_fire_df['smoke_impact'] = filtered_fire_df.apply(\n",
      "/var/folders/js/_m5r698x29j4dvr0w18h6jdm0000gn/T/ipykernel_6915/2844685709.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_fire_df['fire_duration'] = filtered_fire_df['GIS_Acres'].apply(\n",
      "/var/folders/js/_m5r698x29j4dvr0w18h6jdm0000gn/T/ipykernel_6915/2844685709.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_fire_df['amortized_smoke_impact'] = filtered_fire_df['smoke_impact'] / filtered_fire_df['fire_duration']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USGS_Assigned_ID  fire_year    distance  total_acres_burned  \\\n",
      "157             14783       1964  384.142162           28.468121   \n",
      "340             15001       1965  381.724329           29.902511   \n",
      "352             15017       1965  357.252742           11.047444   \n",
      "370             15040       1965  374.861207            2.831538   \n",
      "683             15383       1966  256.234293           12.781395   \n",
      "\n",
      "     amortized_smoke_impact  \n",
      "157            7.432192e-07  \n",
      "340            7.877565e-07  \n",
      "352            3.176369e-07  \n",
      "370            7.652131e-08  \n",
      "683            4.942944e-07  \n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess fire data\n",
    "filtered_fire_df = fire_df[fire_df['distance'] <= MAX_DISTANCE]\n",
    "max_acres_within_radius = filtered_fire_df['GIS_Acres'].max()\n",
    "\n",
    "# Apply smoke impact calculation for each fire\n",
    "filtered_fire_df['smoke_impact'] = filtered_fire_df.apply(\n",
    "    lambda row: get_smoke_impact(row['GIS_Acres'], row['distance'], max_acres_within_radius),\n",
    "    axis=1\n",
    ")\n",
    "filtered_fire_df['fire_duration'] = filtered_fire_df['GIS_Acres'].apply(\n",
    "    lambda acres: estimate_fire_duration(acres, max_acres_within_radius)\n",
    ")\n",
    "\n",
    "\n",
    "# Daily smoke impact for a single fire\n",
    "filtered_fire_df['amortized_smoke_impact'] = filtered_fire_df['smoke_impact'] / filtered_fire_df['fire_duration']\n",
    "\n",
    "filtered_fire_df = filtered_fire_df.rename(columns={'GIS_Acres': 'total_acres_burned', 'Fire_Year': 'fire_year'})\n",
    "\n",
    "# Save per-fire data to CSV\n",
    "filtered_fire_df.to_csv(SI_PER_FIRE_OUTPUT_PATH, index=False)\n",
    "\n",
    "print(filtered_fire_df[['USGS_Assigned_ID','fire_year', 'distance','total_acres_burned','amortized_smoke_impact']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fire_year  avg_daily_smoke_impact  total_amortized_smoke_impact  \\\n",
      "0       1964            7.430301e-08                  7.432192e-07   \n",
      "1       1965            3.939202e-08                  1.181915e-06   \n",
      "2       1966            3.440880e-08                  1.032347e-06   \n",
      "3       1967            5.019618e-07                  1.508150e-05   \n",
      "4       1968            3.645253e-08                  1.093709e-06   \n",
      "\n",
      "   total_acres_burned  \n",
      "0           28.468121  \n",
      "1           43.781494  \n",
      "2           26.964910  \n",
      "3          504.821511  \n",
      "4           40.723316  \n"
     ]
    }
   ],
   "source": [
    "# Calculate total and average daily smoke impact\n",
    "yearly_smoke_impact_df = filtered_fire_df.groupby('fire_year').agg(\n",
    "    total_amortized_smoke_impact=('amortized_smoke_impact', 'sum'),\n",
    "    total_fire_duration=('fire_duration', 'sum'),  # Total days of impact for all fires in the year\n",
    "    total_acres_burned=('total_acres_burned', 'sum')  # Sum of acres burned for each year\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the raw average daily smoke impact per year\n",
    "yearly_smoke_impact_df['avg_daily_smoke_impact'] = (\n",
    "    yearly_smoke_impact_df['total_amortized_smoke_impact'] / yearly_smoke_impact_df['total_fire_duration']\n",
    ")\n",
    "\n",
    "# Save per-year data to CSV\n",
    "yearly_smoke_impact_df.to_csv(SI_PER_YEAR_OUTPUT_PATH, index=False)\n",
    "\n",
    "# Display the results\n",
    "print(yearly_smoke_impact_df[['fire_year', 'avg_daily_smoke_impact', 'total_amortized_smoke_impact', 'total_acres_burned']].head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "512_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
