{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ei_intermediate_file_paths.json') as file_path_file:\n",
    "    file_paths = json.load(file_path_file)\n",
    "\n",
    "\n",
    "SI_PREDS_INPUT_PATH = file_paths.get(\"smoke_impact_model_predictions.csv\")\n",
    "NOAA_BLS_MERGED_INPUT_PATH = file_paths.get(\"stage2_fs_merged_output.csv\")\n",
    "EI_MODEL_INPUT_PATH = file_paths.get(\"ei_model_output\")\n",
    "\n",
    "EI_PREDS_OUTPUT_PATH = file_paths.get(\"economic_impact_model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "si_preds_df = pd.read_csv(SI_PREDS_INPUT_PATH)\n",
    "\n",
    "noaa_bls_historical_df = pd.read_csv(NOAA_BLS_MERGED_INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  predicted_tavg  predicted_prcp  predicted_unemployment_rate\n",
      "0   2021       78.960000        5.326000                    -2.526542\n",
      "1   2022       78.960000        5.326000                    -2.526542\n",
      "2   2023       78.960000        5.326000                    -2.526542\n",
      "3   2024       78.960000        5.326000                    -2.526542\n",
      "4   2025       78.960000        5.326000                    -2.526542\n",
      "5   2026       79.832000        5.067200                    -0.962885\n",
      "6   2027       79.832000        5.067200                    -0.962885\n",
      "7   2028       79.832000        5.067200                    -0.962885\n",
      "8   2029       79.832000        5.067200                    -0.962885\n",
      "9   2030       79.832000        5.067200                    -0.962885\n",
      "10  2031       79.678400        5.538640                    -0.584033\n",
      "11  2032       79.678400        5.538640                    -0.584033\n",
      "12  2033       79.678400        5.538640                    -0.584033\n",
      "13  2034       79.678400        5.538640                    -0.584033\n",
      "14  2035       79.678400        5.538640                    -0.584033\n",
      "15  2036       79.254080        5.668368                     0.475630\n",
      "16  2037       79.254080        5.668368                     0.475630\n",
      "17  2038       79.254080        5.668368                     0.475630\n",
      "18  2039       79.254080        5.668368                     0.475630\n",
      "19  2040       79.254080        5.668368                     0.475630\n",
      "20  2041       78.584896        6.298042                     0.570757\n",
      "21  2042       78.584896        6.298042                     0.570757\n",
      "22  2043       78.584896        6.298042                     0.570757\n",
      "23  2044       78.584896        6.298042                     0.570757\n",
      "24  2045       78.584896        6.298042                     0.570757\n",
      "25  2046       79.261875        5.579650                    -0.605415\n",
      "26  2047       79.261875        5.579650                    -0.605415\n",
      "27  2048       79.261875        5.579650                    -0.605415\n",
      "28  2049       79.261875        5.579650                    -0.605415\n",
      "29  2050       79.261875        5.579650                    -0.605415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate 5-year rolling averages for each variable\n",
    "noaa_bls_historical_df['5yr_avg_tavg'] = noaa_bls_historical_df['noaa_tavg'].rolling(window=5, min_periods=1).mean()\n",
    "noaa_bls_historical_df['5yr_avg_prcp'] = noaa_bls_historical_df['noaa_prcp'].rolling(window=5, min_periods=1).mean()\n",
    "noaa_bls_historical_df['5yr_avg_unemployment_rate'] = noaa_bls_historical_df['bls_pct_diff_laus_unemployment_rate'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Initialize a DataFrame to hold predictions for each year from 2021 to 2050\n",
    "future_years = range(2021, 2051)\n",
    "future_predictions = pd.DataFrame({\n",
    "    'year': future_years,\n",
    "    'predicted_tavg': np.nan,\n",
    "    'predicted_prcp': np.nan,\n",
    "    'predicted_unemployment_rate': np.nan\n",
    "})\n",
    "\n",
    "# Copy historical data into a temporary DataFrame to simulate adding future data\n",
    "temp_data = noaa_bls_historical_df.copy()\n",
    "\n",
    "# Set the 5-year recalculation cycle\n",
    "cycle_length = 5\n",
    "\n",
    "# Loop through each year in the forecast period, applying 5-year recalculations\n",
    "for i, year in enumerate(future_years):\n",
    "    # Assign predictions for this year based on the latest 5-year averages\n",
    "    future_predictions.loc[i, 'predicted_tavg'] = temp_data['5yr_avg_tavg'].iloc[-1]\n",
    "    future_predictions.loc[i, 'predicted_prcp'] = temp_data['5yr_avg_prcp'].iloc[-1]\n",
    "    future_predictions.loc[i, 'predicted_unemployment_rate'] = temp_data['5yr_avg_unemployment_rate'].iloc[-1]\n",
    "\n",
    "    # Every 5 years, update rolling averages using the latest values\n",
    "    if (i + 1) % cycle_length == 0:\n",
    "        # Create a new row for the latest predictions as \"historical\" data\n",
    "        new_row = pd.DataFrame({\n",
    "            'year': [year],\n",
    "            'noaa_tavg': [future_predictions.loc[i, 'predicted_tavg']],\n",
    "            'noaa_prcp': [future_predictions.loc[i, 'predicted_prcp']],\n",
    "            'bls_pct_diff_laus_unemployment_rate': [future_predictions.loc[i, 'predicted_unemployment_rate']]\n",
    "        })\n",
    "        \n",
    "        # Concatenate the new row to `temp_data`\n",
    "        temp_data = pd.concat([temp_data, new_row], ignore_index=True)\n",
    "\n",
    "        # Recalculate the 5-year rolling averages on the updated data\n",
    "        temp_data['5yr_avg_tavg'] = temp_data['noaa_tavg'].rolling(window=5, min_periods=1).mean()\n",
    "        temp_data['5yr_avg_prcp'] = temp_data['noaa_prcp'].rolling(window=5, min_periods=1).mean()\n",
    "        temp_data['5yr_avg_unemployment_rate'] = temp_data['bls_pct_diff_laus_unemployment_rate'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Display the updated predictions with 5-year interval adjustments\n",
    "print(future_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- predicted_prcp\n- predicted_tavg\n- predicted_unemployment_rate\nFeature names seen at fit time, yet now missing:\n- bls_pct_diff_laus_labor_force\n- bls_pct_diff_sae_hrs\n- noaa_prcp\n- scaled_avg_daily_smoke_impact\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m X_future \u001b[38;5;241m=\u001b[39m future_predictions[prediction_features]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Make predictions using the loaded model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m future_predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_economic_impact\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43meconomic_impact_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_future\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/512_proj/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:2127\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m   2113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[1;32m   2114\u001b[0m \n\u001b[1;32m   2115\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2125\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2127\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   2129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2130\u001b[0m     \u001b[38;5;66;03m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[1;32m   2131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/anaconda3/envs/512_proj/lib/python3.11/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/512_proj/lib/python3.11/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- predicted_prcp\n- predicted_tavg\n- predicted_unemployment_rate\nFeature names seen at fit time, yet now missing:\n- bls_pct_diff_laus_labor_force\n- bls_pct_diff_sae_hrs\n- noaa_prcp\n- scaled_avg_daily_smoke_impact\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "with open(EI_MODEL_INPUT_PATH, 'rb') as model_file:\n",
    "    economic_impact_model = pickle.load(model_file)\n",
    "\n",
    "# %%\n",
    "# Prepare the data for prediction\n",
    "# Select the required features for the model\n",
    "prediction_features = ['predicted_tavg', 'predicted_prcp', 'predicted_unemployment_rate']\n",
    "\n",
    "# Ensure future_predictions includes the required columns\n",
    "X_future = future_predictions[prediction_features]\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "future_predictions['predicted_economic_impact'] = economic_impact_model.predict(X_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to the output CSV file\n",
    "future_predictions.to_csv(EI_PREDS_OUTPUT_PATH, index=False)\n",
    "print(f\"Predictions saved to {EI_PREDS_OUTPUT_PATH}\")\n",
    "\n",
    "# %%\n",
    "# Display the predictions\n",
    "print(future_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "512_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
